import random

from custom_ner_base_trainer import BaseNERTrainer
from process_input_file import ProcessFile

class TrainCustomNERModel:

    @staticmethod
    def train_multiple_models(dic_models, label_to_id_path, id_to_label_path,
                            train_sentences_path, train_labels_path, 
                            val_sentences_path, val_labels_path, 
                            train_synthetic_sentences_path=None, train_syntethic_labels_path=None, 
                            version=None, output_dir="ner_model"):
        
        for model, _ in dic_models.items():
            trainer = BaseNERTrainer(model, label_to_id_path, id_to_label_path)
            
            train_original_sentences = ProcessFile.read_json(train_sentences_path)
            train_original_labels = ProcessFile.read_json(train_labels_path)
            train_synthetic_sentences = ProcessFile.read_json(train_synthetic_sentences_path) \
                if train_synthetic_sentences_path is not None else []
            train_synthetic_labels = ProcessFile.read_json(train_syntethic_labels_path) \
                if train_synthetic_sentences_path is not None else []
            
            train_sentences = train_original_sentences + \
                [e for i,e in enumerate(train_synthetic_sentences) if len(e) == len(train_synthetic_labels[i])]
            train_labels = train_original_labels + \
                [e for i,e in enumerate(train_synthetic_labels) if len(e) == len(train_synthetic_sentences[i])]
            
            combined = list(zip(train_sentences, train_labels))
            random.shuffle(combined)
            shuffled_train_sentences, shuffled_train_labels = zip(*combined)

            train_ds = trainer.prepare_dataset(shuffled_train_sentences, shuffled_train_labels)
            val_ds = trainer.prepare_dataset(ProcessFile.read_json(val_sentences_path), ProcessFile.read_json(val_labels_path))

            trainer.train(train_ds, val_ds, output_dir, version)

if __name__ == "__main__":
    label_to_id_path = "input_data/label_to_id.json"
    id_to_label_path = "input_data/id_to_label.json"
    train_sentences_path = "training_data/sentences_train.json"
    train_labels_path = "training_data/labels_train.json"
    val_sentences_path = "training_data/sentences_val.json"
    val_labels_path = "training_data/labels_val.json"

    dic_models = {
        "bert-base-cased": {},
        "dslim/bert-base-NER": {},
        "roberta-base": {}
    }

    # v1 - only use original data
    TrainCustomNERModel.train_multiple_models(dic_models, label_to_id_path, id_to_label_path,
                                    train_sentences_path, train_labels_path,
                                    val_sentences_path, val_labels_path)
    
    # v2 - use synthetic data generated by GPT
    version = "v2"
    train_synthetic_sentences_path = "training_data/sentences_train_v2.json"
    train_sytnetic_labels_path = "training_data/labels_train_v2.json"
    TrainCustomNERModel.train_multiple_models(dic_models, label_to_id_path, id_to_label_path,
                                    train_sentences_path, train_labels_path,
                                    val_sentences_path, val_labels_path,
                                    train_synthetic_sentences_path, train_sytnetic_labels_path,
                                    version)