Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1288/1288 [00:00<00:00, 1590.12 examples/s]
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 276/276 [00:00<00:00, 1492.06 examples/s]
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1288/1288 [00:00<00:00, 1568.62 examples/s]
Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 276/276 [00:00<00:00, 1227.31 examples/s]
C:\Users\luksi\OneDrive\Desktop\Reputeo\base_ner_trainer.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
  0%|                                                                                                       | 0/810 [00:00<?, ?it/s]C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.
  warnings.warn(warn_msg)
  3%|â–ˆâ–ˆâ–Œ                                                                                         | 23/810 [09:34<6:05:41, 27.88s/it]Traceback (most recent call last):
  File "C:\Users\luksi\OneDrive\Desktop\Reputeo\ner_trainer.py", line 42, in <module>
    TrainNERModel.train(trainer_bert_base, train_ds_v1, val_ds_v1, version="v1")
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luksi\OneDrive\Desktop\Reputeo\ner_trainer.py", line 17, in train
    trainer.train(train_ds, val_ds, output_dir, version, epochs, batch_size, seed)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luksi\OneDrive\Desktop\Reputeo\base_ner_trainer.py", line 123, in train
    trainer.train()
    ~~~~~~~~~~~~~^^
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\trainer.py", line 2206, in train
    return inner_training_loop(
        args=args,
    ...<2 lines>...
        ignore_keys_for_eval=ignore_keys_for_eval,
    )
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\trainer.py", line 2548, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\trainer.py", line 3749, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\trainer.py", line 3836, in compute_loss
    outputs = model(**inputs)
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\models\bert\modeling_bert.py", line 1677, in forward
    outputs = self.bert(
        input_ids,
    ...<7 lines>...
        return_dict=return_dict,
    )
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\models\bert\modeling_bert.py", line 996, in forward
    encoder_outputs = self.encoder(
        embedding_output,
    ...<8 lines>...
        return_dict=return_dict,
    )
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\models\bert\modeling_bert.py", line 651, in forward
    layer_outputs = layer_module(
        hidden_states,
    ...<5 lines>...
        output_attentions=output_attentions,
    )
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\modeling_layers.py", line 83, in __call__
    return super().__call__(*args, **kwargs)
           ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\models\bert\modeling_bert.py", line 553, in forward
    self_attention_outputs = self.attention(
        hidden_states,
    ...<3 lines>...
        past_key_value=self_attn_past_key_value,
    )
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\models\bert\modeling_bert.py", line 483, in forward
    self_outputs = self.self(
        hidden_states,
    ...<5 lines>...
        output_attentions,
    )
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\nn\modules\module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\nn\modules\module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\models\bert\modeling_bert.py", line 408, in forward
    attn_output = torch.nn.functional.scaled_dot_product_attention(
        query_layer,
    ...<4 lines>...
        is_causal=is_causal,
    )
KeyboardInterrupt
Exception ignored in atexit callback <function _start_and_connect_service.<locals>.teardown_atexit at 0x0000015F5C30C180>:
Traceback (most recent call last):
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\wandb\sdk\lib\service\service_connection.py", line 54, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\wandb\sdk\lib\service\service_connection.py", line 182, in teardown
    self._router.join()
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\wandb\sdk\interface\router.py", line 75, in join
    self._thread.join()
  File "C:\Program Files\Python313\Lib\threading.py", line 1094, in join
    self._handle.join(timeout)
KeyboardInterrupt:
Exception ignored in atexit callback <bound method finalize._exitfunc of <class 'weakref.finalize'>>:
Traceback (most recent call last):
  File "C:\Program Files\Python313\Lib\weakref.py", line 641, in _exitfunc
    @classmethod
KeyboardInterrupt:
[0m
