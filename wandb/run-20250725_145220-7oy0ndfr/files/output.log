C:\Users\luksi\OneDrive\Desktop\Reputeo\base_ner_trainer.py:157: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
  0%|                                                                                                       | 0/810 [00:00<?, ?it/s]C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.
  warnings.warn(warn_msg)
 10%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                                  | 81/810 [12:33<1:35:21,  7.85s/it]C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\torch\utils\data\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.
{'loss': 0.301, 'grad_norm': 8.638076782226562, 'learning_rate': 1.8790123456790124e-05, 'epoch': 0.62}
  warnings.warn(warn_msg)                                                                                                           
{'eval_loss': 0.12714476883411407, 'eval_precision': 0.7588484301609787, 'eval_recall': 0.8458646616541353, 'eval_f1': 0.7987444688050851, 'eval_accuracy': 0.9579496623695519, 'eval_report': {'LOC': {'precision': 0.768361581920904, 'recall': 0.8717948717948718, 'f1-score': 0.8168168168168168, 'support': 156}, 'MISC': {'precision': 0.6222222222222222, 'recall': 0.8, 'f1-score': 0.7000000000000001, 'support': 105}, 'ORG': {'precision': 0.6891891891891891, 'recall': 0.7611940298507462, 'f1-score': 0.7234042553191488, 'support': 134}, 'PER': {'precision': 0.920863309352518, 'recall': 0.9343065693430657, 'f1-score': 0.927536231884058, 'support': 137}, 'micro avg': {'precision': 0.7512520868113522, 'recall': 0.8458646616541353, 'f1-score': 0.7957559681697612, 'support': 532}, 'macro avg': {'precision': 0.7501590756712083, 'recall': 0.841823867747171, 'f1-score': 0.7919393260050059, 'support': 532}, 'weighted avg': {'precision': 0.7588484301609787, 'recall': 0.8458646616541353, 'f1-score': 0.7987444688050851, 'support': 532}}, 'eval_runtime': 25.7896, 'eval_samples_per_second': 10.702, 'eval_steps_per_second': 0.698, 'epoch': 1.0}
> c:\users\luksi\onedrive\desktop\reputeo\base_ner_trainer.py(36)on_evaluate()
-> breakpoint()
 31  	    def on_evaluate(self, args, state, control, metrics, **kwargs):
 32  	        score = metrics.get("eval_f1")
 33  	        if score is None:
 34  	            return control
 35  	
 36  ->	        breakpoint()
 37  	        if self.best_score is None or score > self.best_score + self.min_delta:
 38  	            self.best_score = score
 39  	            self.wait_count = 0
 40  	        else:
 41  	            self.wait_count += 1
0.7987444688050851
> c:\users\luksi\onedrive\desktop\reputeo\base_ner_trainer.py(37)on_evaluate()
-> if self.best_score is None or score > self.best_score + self.min_delta:
> c:\users\luksi\onedrive\desktop\reputeo\base_ner_trainer.py(38)on_evaluate()
-> self.best_score = score
> c:\users\luksi\onedrive\desktop\reputeo\base_ner_trainer.py(39)on_evaluate()
-> self.wait_count = 0
> c:\users\luksi\onedrive\desktop\reputeo\base_ner_trainer.py(46)on_evaluate()
-> return control
 20%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè                                                                        | 162/810 [27:20<1:46:52,  9.90s/it]Traceback (most recent call last):
{'loss': 0.1128, 'grad_norm': 0.6751688122749329, 'learning_rate': 1.7555555555555556e-05, 'epoch': 1.23}
{'loss': 0.065, 'grad_norm': 1.3481972217559814, 'learning_rate': 1.632098765432099e-05, 'epoch': 1.85}
  File "C:\Users\luksi\OneDrive\Desktop\Reputeo\ner_trainer.py", line 44, in <module>‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:34<00:00,  1.73s/it]
{'eval_loss': 0.11372523009777069, 'eval_precision': 0.8042300591509655, 'eval_recall': 0.8703007518796992, 'eval_f1': 0.8355057502699051, 'eval_accuracy': 0.9648557397176182, 'eval_report': {'LOC': {'precision': 0.8372093023255814, 'recall': 0.9230769230769231, 'f1-score': 0.878048780487805, 'support': 156}, 'MISC': {'precision': 0.7083333333333334, 'recall': 0.8095238095238095, 'f1-score': 0.7555555555555556, 'support': 105}, 'ORG': {'precision': 0.7297297297297297, 'recall': 0.8059701492537313, 'f1-score': 0.7659574468085106, 'support': 134}, 'PER': {'precision': 0.9130434782608695, 'recall': 0.9197080291970803, 'f1-score': 0.9163636363636363, 'support': 137}, 'micro avg': {'precision': 0.801038062283737, 'recall': 0.8703007518796992, 'f1-score': 0.8342342342342343, 'support': 532}, 'macro avg': {'precision': 0.7970789609123785, 'recall': 0.8645697277628861, 'f1-score': 0.8289813548038769, 'support': 532}, 'weighted avg': {'precision': 0.8042300591509655, 'recall': 0.8703007518796992, 'f1-score': 0.8355057502699051, 'support': 532}}, 'eval_runtime': 36.4507, 'eval_samples_per_second': 7.572, 'eval_steps_per_second': 0.494, 'epoch': 2.0}
> c:\users\luksi\onedrive\desktop\reputeo\base_ner_trainer.py(36)on_evaluate()
-> breakpoint()
 31  	    def on_evaluate(self, args, state, control, metrics, **kwargs):
 32  	        score = metrics.get("eval_f1")
 33  	        if score is None:
 34  	            return control
 35  	
 36  ->	        breakpoint()
 37  	        if self.best_score is None or score > self.best_score + self.min_delta:
 38  	            self.best_score = score
 39  	            self.wait_count = 0
 40  	        else:
 41  	            self.wait_count += 1
0.8355057502699051
0.7987444688050851
0.05
0.8487444688050851
0.7997444688050851
    TrainNERModel.train(trainer_bert_base_english_ner, train_ds_v1, val_ds_v1, version="v1")
    ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luksi\OneDrive\Desktop\Reputeo\ner_trainer.py", line 17, in train
    trainer.train(train_ds, val_ds, output_dir, version, epochs, batch_size, seed)
    ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luksi\OneDrive\Desktop\Reputeo\base_ner_trainer.py", line 169, in train
    trainer.train()
    ~~~~~~~~~~~~~^^
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\trainer.py", line 2206, in train
    return inner_training_loop(
        args=args,
    ...<2 lines>...
        ignore_keys_for_eval=ignore_keys_for_eval,
    )
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\trainer.py", line 2657, in _inner_training_loop
    self._maybe_log_save_evaluate(
    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^
        tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, learning_rate=learning_rate
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\trainer.py", line 3096, in _maybe_log_save_evaluate
    metrics = self._evaluate(trial, ignore_keys_for_eval)
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\trainer.py", line 3045, in _evaluate
    metrics = self.evaluate(ignore_keys=ignore_keys_for_eval)
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\trainer.py", line 4229, in evaluate
    self.control = self.callback_handler.on_evaluate(self.args, self.state, self.control, output.metrics)
                   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\trainer_callback.py", line 538, in on_evaluate
    return self.call_event("on_evaluate", args, state, control, metrics=metrics)
           ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\transformers\trainer_callback.py", line 556, in call_event
    result = getattr(callback, event)(
        args,
    ...<8 lines>...
        **kwargs,
    )
  File "C:\Users\luksi\OneDrive\Desktop\Reputeo\base_ner_trainer.py", line 36, in on_evaluate
    breakpoint()
    ~~~~~~~~~~^^
  File "C:\Program Files\Python313\Lib\bdb.py", line 116, in trace_dispatch
    return self.dispatch_opcode(frame, arg)
           ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^
  File "C:\Program Files\Python313\Lib\bdb.py", line 216, in dispatch_opcode
    if self.quitting: raise BdbQuit
                      ^^^^^^^^^^^^^
bdb.BdbQuit
Exception ignored in atexit callback <function _start_and_connect_service.<locals>.teardown_atexit at 0x000001F0A0FE9BC0>:
Traceback (most recent call last):
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\wandb\sdk\lib\service\service_connection.py", line 54, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\wandb\sdk\lib\service\service_connection.py", line 182, in teardown
    self._router.join()
  File "C:\Users\luksi\AppData\Roaming\Python\Python313\site-packages\wandb\sdk\interface\router.py", line 75, in join
    self._thread.join()
  File "C:\Program Files\Python313\Lib\threading.py", line 1094, in join
    self._handle.join(timeout)
KeyboardInterrupt:
[0m
